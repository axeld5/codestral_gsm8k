{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"openai/gsm8k\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Codestral in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "\n",
    "client = MistralClient(api_key=api_key)\n",
    "model = \"codestral-latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_list = [\"\"]*len(dataset[\"test\"])\n",
    "expected_answers = [0]*len(dataset[\"test\"])\n",
    "codestral_code = [\"\"]*len(dataset[\"test\"])\n",
    "codestral_answers = [0]*len(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset[\"test\"])):\n",
    "    math_problem = dataset[\"test\"][i][\"question\"]\n",
    "    expected_answer = int(dataset[\"test\"][i][\"answer\"].split(\"####\")[-1].replace(\",\", \"\").strip())\n",
    "    prompt = f\"\"\"Generate python code to solve the following math problem: \n",
    "\n",
    "    <math_problem> {math_problem} </math_problem>\n",
    "    Make your answer in form of an executable function. Do not code anything outside of the function.\n",
    "    Do not add arguments. Make everything part of the coded function.\n",
    "    Your code MUST output an integer.\n",
    "    Before writing the code, write a paragraph about your understanding of the problem.\n",
    "    Let's think step by step.\"\"\"\n",
    "\n",
    "    response = client.chat(\n",
    "        model=model,\n",
    "        messages=[ChatMessage(role=\"user\", content=prompt)]\n",
    "    )\n",
    "    answer = response.choices[0].message.content    \n",
    "    python_answer = answer.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    function_name = python_answer.split(\"def \")[1].split(\"()\")[0].strip()\n",
    "    func = locals()[function_name]\n",
    "    codestral_answer = func()\n",
    "    if codestral_answer:\n",
    "        result = int(codestral_answer)\n",
    "    else:\n",
    "        result = 0    \n",
    "    problem_list[i] = math_problem\n",
    "    expected_answers[i] = expected_answer\n",
    "    codestral_code[i] = python_answer\n",
    "    codestral_answers[i] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape solutions into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "benchmark_dict = {\"Problem\": problem_list, \"Codestral Code\": codestral_code, \"Expected Answer\": expected_answers, \"Codestral Answer\": codestral_answers}\n",
    "answer_df = pd.DataFrame.from_dict(benchmark_dict)\n",
    "answer_df.to_csv(\"answer_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = (answer_df['Expected Answer'].astype(int) == answer_df['Codestral Answer'].astype(int)).sum()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSM8k pass@1 score: 82%\n"
     ]
    }
   ],
   "source": [
    "benchmark_score = int(count/len(dataset[\"test\"])*100)\n",
    "print(f\"GSM8k pass@1 score: {benchmark_score}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
